{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import pandas as pd\n",
    "# import polars as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.lr_monitor import LearningRateMonitor\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    PREPROCESS = True\n",
    "    SHRINKING = True\n",
    "    SHRINKING_SIZE = 0.01\n",
    "    EPOCHS = 20 #20\n",
    "    BATCH_SIZE = 4096\n",
    "    LR = 1e-4\n",
    "    WD = 1e-6\n",
    "\n",
    "    NBR_FOLDS = 2\n",
    "    SELECTED_FOLDS = [0]\n",
    "\n",
    "    SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import torch\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    #tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds(seed=CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from rdkit import Chem\n",
    "# from torch_geometric.data import Data\n",
    "# import torch\n",
    "# from joblib import Parallel, delayed\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # 读取训练数据\n",
    "# train_raw = pd.read_parquet('data/train.parquet')\n",
    "# # 如果开启了 SHRINKING，按照给定的比例采样数据\n",
    "# if CFG.SHRINKING:\n",
    "#     # 按 'molecule_smiles' 分组，进行采样\n",
    "#     molecules = train_raw['molecule_smiles'].unique()\n",
    "#     sampled_molecules = np.random.choice(molecules, size=int(len(molecules) * CFG.SHRINKING_SIZE), replace=False)\n",
    "    \n",
    "#     # 根据采样的分子过滤原数据\n",
    "#     train_raw = train_raw[train_raw['molecule_smiles'].isin(sampled_molecules)]\n",
    "\n",
    "# smiles = train_raw[train_raw['protein_name'] == 'BRD4']['molecule_smiles'].values\n",
    "# train_smile = pd.DataFrame(smiles)\n",
    "\n",
    "# assert (smiles != train_raw[train_raw['protein_name'] == 'HSA']['molecule_smiles'].values).sum() == 0\n",
    "# assert (smiles != train_raw[train_raw['protein_name'] == 'sEH']['molecule_smiles'].values).sum() == 0\n",
    "\n",
    "# train_smile['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n",
    "# train_smile['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n",
    "# train_smile['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n",
    "\n",
    "# # 将bind1, bind2, bind3三列合并为一个新的列，每个元素是一个长度为3的列表\n",
    "# train_smile['binds_combined'] = train_smile.apply(\n",
    "#     lambda row: [row['bind1'], row['bind2'], row['bind3']], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_smile['binds_combined'][0:10]\n",
    "# # # 检查 'binds_combined' 列表中是否包含 [0, 1, 0]\n",
    "# # target = [0, 1, 0]\n",
    "# # exists = (train_smile['binds_combined'].apply(lambda x: x == target)).any()\n",
    "\n",
    "# # print(exists)  # 如果存在则返回 True，否则返回 False\n",
    "# train_smile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984156/984156 [11:32<00:00, 1421.60it/s]\n",
      "984156it [00:01, 831402.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定义编码 SMILES 为图结构的函数\n",
    "def encode_smile(smile):\n",
    "    graph = smi_to_graph(smile)\n",
    "    return graph\n",
    "\n",
    "# 定义分子转图结构的函数\n",
    "def smi_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # 获取节点特征：这里用原子编号作为特征（你可以根据需要调整）\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features.append(atom.GetAtomicNum())  # 获取原子序数作为特征\n",
    "    \n",
    "    # 获取边的连接信息\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        # bond.GetBeginAtomIdx() 和 bond.GetEndAtomIdx() 返回的是两个原子之间的连接\n",
    "        edge_index.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "        edge_index.append([bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()])\n",
    "    \n",
    "    # 转换成 PyTorch Geometric 格式\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    atom_features = torch.tensor(atom_features, dtype=torch.float).view(-1, 1)  # 节点特征：每个原子对应一个特征\n",
    "    \n",
    "    return Data(x=atom_features, edge_index=edge_index)\n",
    "\n",
    "if CFG.PREPROCESS:\n",
    "    # 读取训练数据\n",
    "    train_raw = pd.read_parquet('data/train.parquet')\n",
    "    # 如果开启了 SHRINKING，按照给定的比例采样数据\n",
    "    if CFG.SHRINKING:\n",
    "        # 按 'molecule_smiles' 分组，进行采样\n",
    "        molecules = train_raw['molecule_smiles'].unique()\n",
    "        sampled_molecules = np.random.choice(molecules, size=int(len(molecules) * CFG.SHRINKING_SIZE), replace=False)\n",
    "        \n",
    "        # 根据采样的分子过滤原数据\n",
    "        train_raw = train_raw[train_raw['molecule_smiles'].isin(sampled_molecules)]\n",
    "\n",
    "\n",
    "    smiles = train_raw[train_raw['protein_name'] == 'BRD4']['molecule_smiles'].values\n",
    "    assert (smiles != train_raw[train_raw['protein_name'] == 'HSA']['molecule_smiles'].values).sum() == 0\n",
    "    assert (smiles != train_raw[train_raw['protein_name'] == 'sEH']['molecule_smiles'].values).sum() == 0\n",
    "\n",
    "    \n",
    "    train_smile = pd.DataFrame(smiles)\n",
    "\n",
    "    train_smile['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n",
    "    train_smile['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n",
    "    train_smile['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n",
    "\n",
    "    # 将bind1, bind2, bind3三列合并为一个新的列，每个元素是一个长度为3的列表\n",
    "    train_smile['binds_combined'] = train_smile.apply(\n",
    "    lambda row: [row['bind1'], row['bind2'], row['bind3']], axis=1)\n",
    "\n",
    "    # 使用 joblib 并行化处理# 对采样后的数据进行图结构转换\n",
    "    graphs = Parallel(n_jobs=60)(delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "\n",
    "\n",
    "    # 提取特征和边\n",
    "    train = []\n",
    "\n",
    "    # 在转换图的过程中，直接对每个图数据添加bind_target\n",
    "    for graph, bind_target in tqdm(zip(graphs, train_smile['binds_combined'])):\n",
    "        # 创建图数据并保存\n",
    "        train.append({\n",
    "            'x': graph.x,              # 节点特征\n",
    "            'edge_index': graph.edge_index,  # 边连接信息\n",
    "            'bind': bind_target        # 当前smile的bind信息\n",
    "        })\n",
    "\n",
    "    # 保存图数据（可以选择保存为 PyTorch 的 Data 对象）\n",
    "    torch.save(train, 'output/train_graphs.pt')\n",
    "\n",
    "    # 对测试集进行同样的处理\n",
    "    # test_raw = pd.read_parquet('data/test.parquet')\n",
    "    # smiles = test_raw['molecule_smiles'].values\n",
    "    # # test_graphs = Parallel(n_jobs=60)(delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "\n",
    "    # test_graphs = Parallel(n_jobs=60)(delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    # 如果开启了 SHRINKING，按照给定的比例采样数据\n",
    "    # if CFG.SHRINKING:\n",
    "    #     test_raw = test_raw.sample(frac=CFG.SHRINKING_SIZE, random_state=CFG.SEED)  # 根据 SHRINKING_SIZE 采样数据\n",
    "    #     smiles = test_raw['molecule_smiles'].values\n",
    "    #     # 对采样后的数据进行图结构转换\n",
    "    #     test_graphs = Parallel(n_jobs=60)(delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    # else:\n",
    "    #     # 使用 joblib 并行化处理\n",
    "    #     test_graphs = Parallel(n_jobs=60)(delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "\n",
    "    # test = []\n",
    "    # for graph in test_graphs:\n",
    "    #     test.append({\n",
    "    #         'x': graph.x,\n",
    "    #         'edge_index': graph.edge_index\n",
    "    #     })\n",
    "\n",
    "    # torch.save(test, 'output/test_graphs.pt')\n",
    "    test = torch.load('output/test_graphs.pt')\n",
    "\n",
    "else:\n",
    "    train = torch.load('output/train_graphs.pt')\n",
    "    test = torch.load('output/test_graphs.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "class MyGNNModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim=6, output_dim=3, lr=1e-3, weight_decay=1e-6):\n",
    "        super(MyGNNModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # 图卷积层\n",
    "        self.conv1 = GCNConv(in_channels=1, out_channels=hidden_dim)  # 第一层GCN\n",
    "        self.conv2 = GCNConv(in_channels=hidden_dim, out_channels=hidden_dim * 2)  # 第二层GCN\n",
    "        self.conv3 = GCNConv(in_channels=hidden_dim * 2, out_channels=hidden_dim * 4)  # 第三层GCN\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc1 = torch.nn.Linear(hidden_dim * 4, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, output_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        #print(x.shape)\n",
    "        #print(edge_index.shape)\n",
    "\n",
    "        # 图卷积操作\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "\n",
    "        # 全局池化（使用最大池化）\n",
    "        x = pyg_nn.global_max_pool(x, data.batch)\n",
    "\n",
    "        # 全连接层\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # 目标标签\n",
    "        y = batch.y\n",
    "\n",
    "        # 前向传播\n",
    "        logits = self(batch)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y = batch.y\n",
    "        logits = self(batch)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jupyter notebook\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\jupyter notebook\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory D:\\zyh\\bddm\\protein_predict\\ckpoint\\GNN exists and is not empty.\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | conv1   | GCNConv | 12     | train\n",
      "1 | conv2   | GCNConv | 84     | train\n",
      "2 | conv3   | GCNConv | 312    | train\n",
      "3 | fc1     | Linear  | 1.6 K  | train\n",
      "4 | fc2     | Linear  | 2.1 K  | train\n",
      "5 | fc3     | Linear  | 99     | train\n",
      "6 | dropout | Dropout | 0      | train\n",
      "--------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n",
      "13        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c766b1c78d2a4b619ad260a331fbe3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167803. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167586. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01326dcf0834a60994a978badf6946f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333110f7617d4041a91e7749edad3ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168205. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167578. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167901. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168360. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167697. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167331. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167480. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167335. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167369. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167510. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167453. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167584. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167511. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168030. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167632. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167413. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167636. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167745. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167259. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 166874. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168003. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167958. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167793. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167645. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167773. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167689. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167866. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167701. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168021. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167651. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167728. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167992. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167378. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167721. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167417. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168252. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168039. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167310. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167836. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167436. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167617. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 9078. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "Metric val_loss improved. New best score: 0.063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fa255c088c42b894da8bb1759b7cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.029 >= min_delta = 0.0. New best score: 0.034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7406d54da8de4e5aaec627624a2e99cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b1cad6068c4a1baeeb5cb41bd719a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa3615798da4d368d6df790f53989a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d21a91770fc47739aec66d87d0f6f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb579d5a1c51411daa84a9e9f70bc8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.034. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Progress: 100%|██████████| 49/49 [00:03<00:00, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score (Average Precision): 0.006941758895845293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import DataLoader\n",
    "# 使用正常训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "FEATURES = [f'enc{i}' for i in range(142)]\n",
    "TARGETS = ['bind1', 'bind2', 'bind3']\n",
    "all_preds = []\n",
    "\n",
    "# # 检查每个graph的bind1, bind2, bind3长度\n",
    "# for graph in train:\n",
    "#     print(graph['bind'])\n",
    "# Assuming `train` is a list of graph data dictionaries\n",
    "# Here, train is a list of dictionaries where each dictionary contains 'x', 'edge_index', and 'y'\n",
    "# train_data = [Data(x=graph['x'], edge_index=graph['edge_index'], y=[torch.tensor(graph['bind'], dtype=torch.float32)]) for graph in train]\n",
    "train_data = [Data(x=graph['x'], edge_index=graph['edge_index'], y=torch.tensor([graph['bind']], dtype=torch.float32)) for graph in train]\n",
    "\n",
    "\n",
    "\n",
    "# Train-validation split (splitting the list of graphs)\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now we can create DataLoader from these lists\n",
    "train_loader = DataLoader(train_data, batch_size=CFG.BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=CFG.BATCH_SIZE)\n",
    "\n",
    "# # Convert pandas dataframes to PyTorch tensors\n",
    "# X_train = torch.tensor(train.loc[train_idx, FEATURES].values, dtype=torch.int)\n",
    "# y_train = torch.tensor(train.loc[train_idx, TARGETS].values, dtype=torch.float16)\n",
    "# X_val = torch.tensor(train.loc[valid_idx, FEATURES].values, dtype=torch.int)\n",
    "# y_val = torch.tensor(train.loc[valid_idx, TARGETS].values, dtype=torch.float16)\n",
    "\n",
    "# # Create TensorDatasets\n",
    "# train_dataset = TensorDataset(X_train, y_train)\n",
    "# valid_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "# # Create DataLoaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=CFG.BATCH_SIZE)\n",
    "\n",
    "# Initialize the model\n",
    "model = MyGNNModel(lr=CFG.LR, weight_decay=CFG.WD)\n",
    "\n",
    "# Define callbacks\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, verbose=True)\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", dirpath=\"./ckpoint/GNN\", filename=\"model\", save_top_k=1, mode=\"min\")\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "# Trainer setup\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=CFG.EPOCHS,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback, lr_monitor],\n",
    "    devices=1,\n",
    "    accelerator=\"cpu\",  # Adjust based on your hardware\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "\n",
    "\n",
    "# Load model onto the GPU\n",
    "model = MyGNNModel.load_from_checkpoint(checkpoint_callback.best_model_path).to(device)\n",
    "print(\"load ok\")\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Perform batched inference with data also on GPU\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for batch in tqdm(valid_loader, desc=\"Validation Progress\"):\n",
    "        # Access the graph data in the batch\n",
    "        batch_x = batch.x.to(device)  # Node features (x)\n",
    "        # print(batch_x.shape)\n",
    "        batch_edge_index = batch.edge_index.to(device)  # Edge index (edge_index)\n",
    "        # print(batch_edge_index.shape)\n",
    "        batch_y = batch.y.to(device)  # Ground truth labels (y)\n",
    "        # print(batch_y.shape)\n",
    "\n",
    "        # Predict for the batch\n",
    "        preds = model(batch.to(device))  # Model expects x and edge_index\n",
    "\n",
    "        # Move predictions and targets to CPU for concatenation\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(batch_y.cpu())\n",
    "\n",
    "# Concatenate all batches into single tensors\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# Compute the score\n",
    "score = average_precision_score(all_targets.numpy(), all_preds.numpy(), average='micro')\n",
    "print('Validation Score (Average Precision):', score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.1087, -5.5801, -4.7407])\n",
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(all_preds[25])\n",
    "print(all_targets[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_167416\\162507663.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = [Data(x=torch.tensor(graph['x'], dtype=torch.float32),\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_167416\\162507663.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(graph['edge_index'], dtype=torch.long)) for graph in test]\n",
      "d:\\jupyter notebook\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Test Data Inference Progress: 100%|██████████| 409/409 [00:35<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed. Predictions shape: (1674896, 3)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# 假设 test 数据是一个包含多个 graph 的列表，每个 graph 是一个 Data 对象\n",
    "test_data = [Data(x=torch.tensor(graph['x'], dtype=torch.float32), \n",
    "                  edge_index=torch.tensor(graph['edge_index'], dtype=torch.long)) for graph in test]\n",
    "\n",
    "\n",
    "# test_dataset = TensorDataset(test_data)\n",
    "test_loader = DataLoader(test_data,batch_size=CFG.BATCH_SIZE,shuffle=False)\n",
    "\n",
    "# Perform batched inference\n",
    "all_preds_test = []\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for batch in tqdm(test_loader, desc=\"Test Data Inference Progress\"):\n",
    "        # Predict for the batch\n",
    "        preds = model(batch.to(device))\n",
    "        \n",
    "        # Move predictions to CPU and append to results\n",
    "        all_preds_test.append(preds.cpu())  \n",
    "\n",
    "# Concatenate all predictions into a single tensor\n",
    "final_preds = torch.cat(all_preds_test, dim=0)\n",
    "\n",
    "# Min-Max Normalization to scale predictions between 0 and 1\n",
    "min_val = final_preds.min()\n",
    "max_val = final_preds.max()\n",
    "final_preds = (final_preds - min_val) / (max_val - min_val)\n",
    "\n",
    "# Convert to NumPy for further processing\n",
    "final_preds = final_preds.numpy()\n",
    "\n",
    "# Output the final predictions\n",
    "print(\"Inference completed. Predictions shape:\", final_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_167416\\1077872100.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.5623296 0.5623296 0.5623296 ... 0.5623296 0.5623296 0.5623296]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tst.loc[tst['protein_name']=='BRD4', 'binds'] = final_preds[(tst['protein_name']=='BRD4').values, 0]\n"
     ]
    }
   ],
   "source": [
    "tst = pd.read_parquet('data/test.parquet')\n",
    "tst['binds'] = 0\n",
    "tst.loc[tst['protein_name']=='BRD4', 'binds'] = final_preds[(tst['protein_name']=='BRD4').values, 0]\n",
    "tst.loc[tst['protein_name']=='HSA', 'binds'] = final_preds[(tst['protein_name']=='HSA').values, 1]\n",
    "tst.loc[tst['protein_name']=='sEH', 'binds'] = final_preds[(tst['protein_name']=='sEH').values, 2]\n",
    "tst[['id', 'binds']].to_csv('submission_gnn.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
